{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MoLPC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbBVh5uuLP5Rn7He0qbZ0P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patrickbryant1/MoLPC/blob/master/MoLPC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CCt5QZ0kIeNn",
        "outputId": "d48d151a-c061-46df-91ab-260fbf227295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting biopython==1.79\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 33.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython==1.79) (1.21.6)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.79\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting JAX==0.2.14\n",
            "  Downloading jax-0.2.14.tar.gz (669 kB)\n",
            "\u001b[K     |████████████████████████████████| 669 kB 33.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from JAX==0.2.14) (1.21.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from JAX==0.2.14) (1.0.0)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.7/dist-packages (from JAX==0.2.14) (3.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->JAX==0.2.14) (1.15.0)\n",
            "Building wheels for collected packages: JAX\n",
            "  Building wheel for JAX (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for JAX: filename=jax-0.2.14-py3-none-any.whl size=771352 sha256=6daf3dcd902d7a794230f909279517bf1e729e766941c0f4591bf630c91e93e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/bd/25/923906d87d262ee0be5c68b248d1a8249d028603582a256266\n",
            "Successfully built JAX\n",
            "Installing collected packages: JAX\n",
            "  Attempting uninstall: JAX\n",
            "    Found existing installation: jax 0.3.8\n",
            "    Uninstalling jax-0.3.8:\n",
            "      Successfully uninstalled jax-0.3.8\n",
            "Successfully installed JAX-0.2.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dm-haiku==0.0.4\n",
            "  Downloading dm_haiku-0.0.4-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 32.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.4) (1.0.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.4) (0.8.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.4) (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.4) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.1->dm-haiku==0.0.4) (1.15.0)\n",
            "Installing collected packages: dm-haiku\n",
            "Successfully installed dm-haiku-0.0.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ml-collections==0.1.0\n",
            "  Downloading ml_collections-0.1.0-py3-none-any.whl (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ml-collections==0.1.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from ml-collections==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml-collections==0.1.0) (0.5.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from ml-collections==0.1.0) (3.13)\n",
            "Installing collected packages: ml-collections\n",
            "Successfully installed ml-collections-0.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chex==0.0.7\n",
            "  Downloading chex-0.0.7-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.7) (0.1.7)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.7) (1.0.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.7) (0.11.2)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.7) (0.3.7+cuda11.cudnn805)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.7) (1.21.6)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.7) (0.2.14)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.9.0->chex==0.0.7) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->chex==0.0.7) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->chex==0.0.7) (2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->chex==0.0.7) (1.4.1)\n",
            "Installing collected packages: chex\n",
            "Successfully installed chex-0.0.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dm-tree==0.1.6\n",
            "  Downloading dm_tree-0.1.6-cp37-cp37m-manylinux_2_24_x86_64.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from dm-tree==0.1.6) (1.15.0)\n",
            "Installing collected packages: dm-tree\n",
            "  Attempting uninstall: dm-tree\n",
            "    Found existing installation: dm-tree 0.1.7\n",
            "    Uninstalling dm-tree-0.1.7:\n",
            "      Successfully uninstalled dm-tree-0.1.7\n",
            "Successfully installed dm-tree-0.1.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tree"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting immutabledict==2.0.0\n",
            "  Downloading immutabledict-2.0.0-py3-none-any.whl (4.0 kB)\n",
            "Installing collected packages: immutabledict\n",
            "Successfully installed immutabledict-2.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.19.5\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 35.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas==1.3.4\n",
            "  Downloading pandas-1.3.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 27.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.4) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.4) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.4) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.4) (1.15.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "Successfully installed pandas-1.3.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scipy==1.7.0\n",
            "  Downloading scipy-1.7.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.5 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy==1.7.0) (1.19.5)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-cpu==2.5.0\n",
            "  Downloading tensorflow_cpu-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (168.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 168.3 MB 42 kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (3.17.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (1.19.5)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (1.6.3)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (3.1.0)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 65.1 MB/s \n",
            "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (2.8.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (0.2.0)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (1.1.0)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 45.2 MB/s \n",
            "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (0.37.1)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 74.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 65.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow-cpu==2.5.0) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-cpu==2.5.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-cpu==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-cpu==2.5.0) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-cpu==2.5.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow-cpu==2.5.0) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow-cpu==2.5.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-cpu==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-cpu==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-cpu==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-cpu==2.5.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-cpu==2.5.0) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-cpu==2.5.0) (3.2.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68722 sha256=9e26394d7ec47f0c645db3df059c182202ac0ba8f58965996e4f8ee9da2ddfef\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, grpcio, absl-py, wrapt, tensorflow-estimator, keras-nightly, gast, flatbuffers, tensorflow-cpu\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.3\n",
            "    Uninstalling grpcio-1.46.3:\n",
            "      Successfully uninstalled grpcio-1.46.3\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.0.0\n",
            "    Uninstalling absl-py-1.0.0:\n",
            "      Successfully uninstalled absl-py-1.0.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 2.5.0 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.4.0 grpcio-1.34.1 keras-nightly-2.5.0.dev2021032900 tensorflow-cpu-2.5.0 tensorflow-estimator-2.5.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "absl",
                  "typing_extensions",
                  "wrapt"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Install dependencies\n",
        "%pip install biopython==1.79\n",
        "%pip install JAX==0.2.14\n",
        "%pip install dm-haiku==0.0.4\n",
        "%pip install ml-collections==0.1.0\n",
        "%pip install chex==0.0.7\n",
        "%pip install dm-tree==0.1.6\n",
        "%pip install immutabledict==2.0.0\n",
        "%pip install numpy==1.19.5\n",
        "%pip install pandas==1.3.4\n",
        "%pip install scipy==1.7.0\n",
        "%pip install tensorflow-cpu==2.5.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone MoLPC git\n",
        "import shutil\n",
        "shutil.rmtree('/content/MoLPC', ignore_errors=True)\n",
        "!git clone https://github.com/patrickbryant1/MoLPC.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YfNo5Thp6KJ",
        "outputId": "abd1c4ce-8d62-4ffc-c0ed-79c5356612ad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MoLPC'...\n",
            "remote: Enumerating objects: 244, done.\u001b[K\n",
            "remote: Counting objects: 100% (244/244), done.\u001b[K\n",
            "remote: Compressing objects: 100% (184/184), done.\u001b[K\n",
            "remote: Total 244 (delta 101), reused 194 (delta 55), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (244/244), 34.73 MiB | 14.06 MiB/s, done.\n",
            "Resolving deltas: 100% (101/101), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Run the assembly pipeline\n",
        "import sys, os\n",
        "from google.colab import files\n",
        "sys.path.insert(0,'/content/MoLPC/src')\n",
        "#@title Default title text\n",
        "ID = \"1A8R\" #@param {type:\"string\"}\n",
        "SUBSIZE = 3 #@param {type:\"integer\"} #What order the subcomplexes should be (2 or 3)\n",
        "GET_ALL = 1 #@param {type:\"integer\"} #If to get all interactions (1) or not (0) - when the interactions are known\n",
        "#Get the csvs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "DATADIR='/content/MoLPC/data/test/'\n",
        "USEQS=pd.read_csv(DATADIR+ID+'_useqs.csv')\n",
        "CHAINS=pd.read_csv(DATADIR+ID+'_chains.csv')\n",
        "INTERACTIONS='' #Leave empty if the interactions are not known - here they are not used. See the file $DATADIR/$ID'_ints.csv' to how to supply such a file\n",
        "MSADIR=DATADIR+'/'\n",
        "OUTDIR=\"/content/gdrive/MyDrive/\"\n",
        "#Mount the drive to be able to save files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') #All the output will be written here"
      ],
      "metadata": {
        "id": "pCCU8gLUL8dq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b91bf9-0937-4e82-9395-b53402fb228d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 1: MSA PIPELINE\n",
        "#@markdown Now, a default MSA is read in - no search is performed here\n",
        "\n",
        "#@markdown Write the Paired and Block Diagonalized MSAs to predict sub-components\n",
        "from preprocess import preprocess_colab\n",
        "preprocess_colab.create_folder_structure(MSADIR, ID, OUTDIR, USEQS, INTERACTIONS, CHAINS, GET_ALL, SUBSIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdefazeqnSrp",
        "outputId": "8b61d9a1-548e-436d-da8f-9b1bd61850c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating all interactions of size 3 ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 2: FOLDING PIPELINE\n",
        "#Create structure dir\n",
        "STRUCTURE_DIR=OUTDIR+\"AF/\"\n",
        "if not os.path.exists(STRUCTURE_DIR):\n",
        "  os.mkdir(STRUCTURE_DIR)\n",
        "#Get the sub_ids and lengths\n",
        "import glob\n",
        "files = glob.glob(OUTDIR+'*.fasta')\n",
        "sub_ids = {}\n",
        "for filename in files:\n",
        "  with open(filename, 'r') as file:\n",
        "    for line in file:\n",
        "      line = line.rstrip()[1:].split('|')\n",
        "      sub_ids[line[0]]=line[-1].split('-')[:-1]\n",
        "      break\n",
        "\n",
        "#@markdown Get the AF2 params\n",
        "import shutil\n",
        "PARAMS=STRUCTURE_DIR+'params/'\n",
        "if not os.path.exists(PARAMS):\n",
        "  os.mkdir(PARAMS)\n",
        "  !wget https://storage.googleapis.com/alphafold/alphafold_params_2021-07-14.tar \n",
        "  shutil.move('/content/alphafold_params_2021-07-14.tar', PARAMS)\n",
        "  #Extract\n",
        "  !tar -xvf /content/gdrive/MyDrive/AF/params/alphafold_params_2021-07-14.tar -C /content/gdrive/MyDrive/AF/params/"
      ],
      "metadata": {
        "id": "fifktm5fz5KR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Predict the subcomponents\n",
        "sys.path.insert(0,'/content/MoLPC/src/AF2')\n",
        "from AF2 import run_alphafold_colab\n",
        "##### AF2 CONFIGURATION #####\n",
        "PARAM=STRUCTURE_DIR\n",
        "PRESET='full_dbs' #Choose preset model configuration - no ensembling (full_dbs) and (reduced_dbs) or 8 model ensemblings (casp14).\n",
        "MAX_RECYCLES=10 #max_recycles (default=3)\n",
        "MODEL_NAME='model_1' #model_1_ptm\n",
        "\n",
        "#Go through all subcomponents and predict their structure\n",
        "for sub_id in sub_ids:\n",
        "  ####Get fasta file####\n",
        "  FASTAFILE=OUTDIR+sub_id+'.fasta'\n",
        "  ####Get chain break#### Note! This is now set for trimer subcomponents\n",
        "  CB=np.cumsum([int(x) for x in sub_ids[sub_id]])\n",
        "  CB = [str(x) for x in CB]\n",
        "  ####Get MSAs####\n",
        "  #HHblits paired\n",
        "  PAIREDMSA=OUTDIR+sub_id+'_paired.a3m'\n",
        "  ##HHblits block diagonalized\n",
        "  BLOCKEDMSA=OUTDIR+sub_id+'_blocked.a3m'\n",
        "  MSAS=[PAIREDMSA,BLOCKEDMSA] #Comma separated list of msa paths\n",
        "  print(sub_id,CB, MSAS)\n",
        "  run_alphafold_colab.main([MODEL_NAME], 1, MAX_RECYCLES, STRUCTURE_DIR, FASTAFILE, sub_id, MSAS, CB, OUTDIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw0kw1KT3Sd0",
        "outputId": "d8e833d1-c6c9-4b1a-e472-d13457417432"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1A8R_1-1-1 ['221', '442'] ['/content/gdrive/MyDrive/1A8R_1-1-1_paired.a3m', '/content/gdrive/MyDrive/1A8R_1-1-1_blocked.a3m']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 3: ASSEMBLY PIPELINE\n",
        "from complex_assembly import prepare_assembly_colab\n",
        "COMPLEXDIR=OUTDIR+'/assembly/complex/' #Where all the output for the complex assembly will be directed\n",
        "#Make complex directory\n",
        "if not os.path.exists(COMPLEXDIR):\n",
        "  os.mkdir(OUTDIR+'/assembly')\n",
        "  os.mkdir(COMPLEXDIR)\n",
        "#Rewrite the FoldDock preds to have separate chains according to the fasta file seqlens\n",
        "files = glob.glob(OUTDIR+ID+'*/*1.pdb')\n",
        "if len(files)>0:\n",
        "    for pdbname in files:\n",
        "        chains = prepare_assembly_colab.read_all_chains_coords(pdbname)\n",
        "        if len(chains.keys())>1:\n",
        "            continue\n",
        "        subid = pdbname.split('/')[-2]\n",
        "        print(subid)\n",
        "        #Rewrite the files\n",
        "        prepare_assembly_colab.write_pdb(chains, pdbname.split('.')[0]+'_rw'+'.pdb')\n",
        "\n",
        "#Copy the predictions to reflect all chains\n",
        "prepare_assembly_colab.copy_uints(ID, OUTDIR, OUTDIR+'/assembly/', USEQS,INTERACTIONS, CHAINS, GET_ALL, SUBSIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Uzmm0xcibSG",
        "outputId": "88ed8961-02cd-4fcd-d5c2-9ed308a98b39"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1A8R_1-1-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Rewrite AF predicted complexes to have proper numbering and chain labels\n",
        "files = glob.glob(OUTDIR+'/assembly/'+ID+'*/*.pdb')\n",
        "if len(files)>0:\n",
        "    for pdbname in files:\n",
        "        chains = prepare_assembly_colab.read_all_chains_coords(pdbname)\n",
        "        subid = pdbname.split('/')[-2]\n",
        "        chain_names = subid.split('_')[-1]\n",
        "        #Rewrite the files\n",
        "        prepare_assembly_colab.write_pdb_chain_labels(chains, chain_names, OUTDIR+'/assembly/'+subid+'.pdb')\n"
      ],
      "metadata": {
        "id": "4TK7V2K7HajJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write all pairs\n",
        "PAIRDIR=OUTDIR+'/assembly/'\n",
        "META=OUTDIR+'/assembly/meta.csv' #where to write all interactions\n",
        "#It is necessary that the first unique chain is named A-..N for and the second N-... and so on\n",
        "if not os.path.exists(PAIRDIR):\n",
        "  os.mkdir(PAIRDIR)\n"
      ],
      "metadata": {
        "id": "M3aFJ-3Klhaz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from complex_assembly import rewrite_fd\n",
        "\n",
        "\n",
        "#Copy all predicted unique chain interactions to reflect all possible interactions\n",
        "SUB_PDBDIR=$STRUCTURE_DIR/\n",
        "OUTDIR=$DATADIR/assembly/\n",
        "singularity exec $SINGIMG python3 $CODEDIR/copy_preds.py --complex_id $ID --pdbdir $SUB_PDBDIR --outdir $OUTDIR \\\n",
        "--useqs $USEQS --subsize $SUBSIZE --interactions $INTERACTIONS --intchain2seq $CHAINS --get_all $GET_ALL\n",
        "\n",
        "#Rewrite AF predicted complexes to have proper numbering and chain labels\n",
        "PDBDIR=$OUTDIR\n",
        "singularity exec $SINGIMG python3 $CODEDIR/rewrite_af_pdb.py --pdbdir $PDBDIR --pdb_id $ID --outdir $OUTDIR\n",
        "\n",
        "#Write all pairs\n",
        "PAIRDIR=$PDBDIR/pairs/\n",
        "META=$PDBDIR/meta.csv #where to write all interactions\n",
        "#It is necessary that the first unique chain is named A-..N for and the second N-... and so on\n",
        "mkdir $PAIRDIR\n",
        "#Glob for all files with each chain in order (A,B,C,D) A-->B,C,D; B--> C,D; C-->D\n",
        "singularity exec $SINGIMG python3 $CODEDIR/write_all_pairs.py --pdbdir $PDBDIR --pairdir $PAIRDIR --meta $META \\\n",
        "--interactions $INTERACTIONS --get_all $GET_ALL\n",
        "\n",
        "#Assemble from pairs\n",
        "#Find the best non-overlapping path that connect all nodes using Monte Carlo Tree search\n",
        "PLDDTDIR=$PDBDIR/plddt/\n",
        "CHAIN_SEQS=$PDBDIR/$ID'_chains.csv' #Updated chain seqs\n",
        "singularity exec $SINGIMG python3 $CODEDIR/mcts.py --network $META \\\n",
        "--pairdir $PAIRDIR --plddt_dir $PLDDTDIR \\\n",
        "--useqs $USEQS --chain_seqs $CHAIN_SEQS \\\n",
        "--outdir $COMPLEXDIR\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "qY3K-pKQgO4Z",
        "outputId": "7a84ea3e-9e33-4754-ce24-9cffce9e0081"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-323a905bc9c5>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    SUB_PDBDIR=$STRUCTURE_DIR/\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VSK4qZGIHZsF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}