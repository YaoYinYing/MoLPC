{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MoLPC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1qXn1IeGgK9K0XUgS_65EGHCYlL8QQs3F",
      "authorship_tag": "ABX9TyMAVy7wEN5o8l3N8v8mFsoe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patrickbryant1/MoLPC/blob/master/MoLPC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCt5QZ0kIeNn",
        "cellView": "form",
        "outputId": "c2c4737c-99e3-4a6b-b91d-db57378681d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting biopython==1.79\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython==1.79) (1.21.6)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.79\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting JAX==0.2.14\n",
            "  Downloading jax-0.2.14.tar.gz (669 kB)\n",
            "\u001b[K     |████████████████████████████████| 669 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from JAX==0.2.14) (1.21.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from JAX==0.2.14) (1.0.0)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.7/dist-packages (from JAX==0.2.14) (3.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->JAX==0.2.14) (1.15.0)\n",
            "Building wheels for collected packages: JAX\n",
            "  Building wheel for JAX (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for JAX: filename=jax-0.2.14-py3-none-any.whl size=771352 sha256=94c22c2a4005da056c9511a11e117b5510c450f39faca5ea2e781f7566b2703d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/bd/25/923906d87d262ee0be5c68b248d1a8249d028603582a256266\n",
            "Successfully built JAX\n",
            "Installing collected packages: JAX\n",
            "  Attempting uninstall: JAX\n",
            "    Found existing installation: jax 0.3.8\n",
            "    Uninstalling jax-0.3.8:\n",
            "      Successfully uninstalled jax-0.3.8\n",
            "Successfully installed JAX-0.2.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dm-haiku==0.0.4\n",
            "  Downloading dm_haiku-0.0.4-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 10.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.4) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.4) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.4) (4.2.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku==0.0.4) (0.8.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.1->dm-haiku==0.0.4) (1.15.0)\n",
            "Installing collected packages: dm-haiku\n",
            "Successfully installed dm-haiku-0.0.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ml-collections==0.1.0\n",
            "  Downloading ml_collections-0.1.0-py3-none-any.whl (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ml-collections==0.1.0) (1.15.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml-collections==0.1.0) (0.5.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from ml-collections==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from ml-collections==0.1.0) (3.13)\n",
            "Installing collected packages: ml-collections\n",
            "Successfully installed ml-collections-0.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chex==0.0.7\n",
            "  Downloading chex-0.0.7-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 844 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.7) (1.21.6)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.7) (0.2.14)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.7) (1.0.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.7) (0.11.2)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.7) (0.3.7+cuda11.cudnn805)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex==0.0.7) (0.1.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.9.0->chex==0.0.7) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->chex==0.0.7) (3.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->chex==0.0.7) (1.4.1)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->chex==0.0.7) (2.0)\n",
            "Installing collected packages: chex\n",
            "Successfully installed chex-0.0.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dm-tree==0.1.6\n",
            "  Downloading dm_tree-0.1.6-cp37-cp37m-manylinux_2_24_x86_64.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from dm-tree==0.1.6) (1.15.0)\n",
            "Installing collected packages: dm-tree\n",
            "  Attempting uninstall: dm-tree\n",
            "    Found existing installation: dm-tree 0.1.7\n",
            "    Uninstalling dm-tree-0.1.7:\n",
            "      Successfully uninstalled dm-tree-0.1.7\n",
            "Successfully installed dm-tree-0.1.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting immutabledict==2.0.0\n",
            "  Downloading immutabledict-2.0.0-py3-none-any.whl (4.0 kB)\n",
            "Installing collected packages: immutabledict\n",
            "Successfully installed immutabledict-2.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.19.5\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 14.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas==1.3.4\n",
            "  Downloading pandas-1.3.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 16.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.4) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.4) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.4) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.4) (1.15.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "Successfully installed pandas-1.3.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scipy==1.7.0\n",
            "  Downloading scipy-1.7.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.5 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy==1.7.0) (1.19.5)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-cpu==2.5.0\n",
            "  Downloading tensorflow_cpu-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (168.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 168.3 MB 48 kB/s \n",
            "\u001b[?25hCollecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 57.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (1.6.3)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 19.3 MB/s \n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (0.2.0)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (1.19.5)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (0.37.1)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (3.17.3)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (2.8.0)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (1.1.2)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (3.3.0)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow-cpu==2.5.0) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-cpu==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-cpu==2.5.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-cpu==2.5.0) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-cpu==2.5.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow-cpu==2.5.0) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow-cpu==2.5.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-cpu==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-cpu==2.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-cpu==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-cpu==2.5.0) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-cpu==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-cpu==2.5.0) (3.2.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68723 sha256=d8901fa087077253f7f72531853f12eb000effdb5d07e37f8d923ed7635b29f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, grpcio, absl-py, wrapt, tensorflow-estimator, keras-nightly, gast, flatbuffers, tensorflow-cpu\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n"
          ]
        }
      ],
      "source": [
        "#@title Install dependencies\n",
        "#@markdown You will have to restart the runtime after this finishes to include the new packages.\n",
        "#@markdown In the menu above do: Runtime --> Restart runtime \n",
        "\n",
        "#@markdown Make sure your runtime is GPU: Runtime --> Change runtime type --> Hardware accelerator (set to GPU)\n",
        "!pip install biopython==1.79\n",
        "!pip install JAX==0.2.14\n",
        "!pip install dm-haiku==0.0.4\n",
        "!pip install ml-collections==0.1.0\n",
        "!pip install chex==0.0.7\n",
        "!pip install dm-tree==0.1.6\n",
        "!pip install immutabledict==2.0.0\n",
        "!pip install numpy==1.19.5\n",
        "!pip install pandas==1.3.4\n",
        "!pip install scipy==1.7.0\n",
        "!pip install tensorflow-cpu==2.5.0\n",
        "!pip install py3Dmol"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone MoLPC git\n",
        "import shutil\n",
        "shutil.rmtree('/content/MoLPC', ignore_errors=True)\n",
        "!git clone https://github.com/patrickbryant1/MoLPC.git"
      ],
      "metadata": {
        "id": "0YfNo5Thp6KJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84095447-7aa0-4916-eba2-a87d470f8dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MoLPC'...\n",
            "remote: Enumerating objects: 327, done.\u001b[K\n",
            "remote: Counting objects: 100% (327/327), done.\u001b[K\n",
            "remote: Compressing objects: 100% (240/240), done.\u001b[K\n",
            "remote: Total 327 (delta 161), reused 239 (delta 82), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (327/327), 35.36 MiB | 15.81 MiB/s, done.\n",
            "Resolving deltas: 100% (161/161), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Run the assembly pipeline\n",
        "import sys, os\n",
        "from google.colab import files\n",
        "sys.path.insert(0,'/content/MoLPC/src')\n",
        "#@title Default title text\n",
        "ID = \"1A8R\" #@param {type:\"string\"}\n",
        "SUBSIZE = 3 #@param {type:\"integer\"} #What order the subcomplexes should be (2 or 3)\n",
        "GET_ALL = 1 #@param {type:\"integer\"} #If to get all interactions (1) or not (0) - when the interactions are known\n",
        "#Get the csvs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "DATADIR='/content/MoLPC/data/test/'\n",
        "USEQS=pd.read_csv(DATADIR+ID+'_useqs.csv')\n",
        "CHAINS=pd.read_csv(DATADIR+ID+'_chains.csv')\n",
        "INTERACTIONS='' #Leave empty if the interactions are not known - here they are not used. See the file $DATADIR/$ID'_ints.csv' to how to supply such a file\n",
        "MSADIR=DATADIR+'/'\n",
        "OUTDIR=\"/content/gdrive/MyDrive/\"\n",
        "#Mount the drive to be able to save files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') #All the output will be written here\n",
        "#@markdown You have to allow to connect to Google drive in order to run MoLPC."
      ],
      "metadata": {
        "id": "pCCU8gLUL8dq",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "889ad1de-cf68-4d3d-94d8-29f43665e9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 1: MSA PIPELINE\n",
        "#@markdown Now, a default MSA is read in - no search is performed here\n",
        "\n",
        "#@markdown Write the Paired and Block Diagonalized MSAs to predict sub-components\n",
        "from preprocess import preprocess_colab\n",
        "preprocess_colab.create_folder_structure(MSADIR, ID, OUTDIR, USEQS, INTERACTIONS, CHAINS, GET_ALL, SUBSIZE)"
      ],
      "metadata": {
        "id": "gdefazeqnSrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a2a526-9a75-4445-9ed1-fcb26928b6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating all interactions of size 3 ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 2: FOLDING PIPELINE\n",
        "#Create structure dir\n",
        "STRUCTURE_DIR=OUTDIR+\"AF/\"\n",
        "if not os.path.exists(STRUCTURE_DIR):\n",
        "  os.mkdir(STRUCTURE_DIR)\n",
        "#Get the sub_ids and lengths\n",
        "import glob\n",
        "files = glob.glob(OUTDIR+'*.fasta')\n",
        "sub_ids = {}\n",
        "for filename in files:\n",
        "  with open(filename, 'r') as file:\n",
        "    for line in file:\n",
        "      line = line.rstrip()[1:].split('|')\n",
        "      sub_ids[line[0]]=line[-1].split('-')[:-1]\n",
        "      break\n",
        "\n",
        "#@markdown Get the AF2 params\n",
        "import shutil\n",
        "PARAMS=STRUCTURE_DIR+'params/'\n",
        "if not os.path.exists(PARAMS):\n",
        "  os.mkdir(PARAMS)\n",
        "  !wget https://storage.googleapis.com/alphafold/alphafold_params_2021-07-14.tar \n",
        "  shutil.move('/content/alphafold_params_2021-07-14.tar', PARAMS)\n",
        "  #Extract\n",
        "  !tar -xvf /content/gdrive/MyDrive/AF/params/alphafold_params_2021-07-14.tar -C /content/gdrive/MyDrive/AF/params/"
      ],
      "metadata": {
        "id": "fifktm5fz5KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Predict the subcomponents\n",
        "sys.path.insert(0,'/content/MoLPC/src/AF2')\n",
        "from AF2 import run_alphafold_colab\n",
        "##### AF2 CONFIGURATION #####\n",
        "PARAM=STRUCTURE_DIR\n",
        "PRESET='full_dbs' #Choose preset model configuration - no ensembling (full_dbs) and (reduced_dbs) or 8 model ensemblings (casp14).\n",
        "MAX_RECYCLES=10 #max_recycles (default=3)\n",
        "MODEL_NAME='model_1' #model_1_ptm\n",
        "\n",
        "#Go through all subcomponents and predict their structure\n",
        "for sub_id in sub_ids:\n",
        "  ####Get fasta file####\n",
        "  FASTAFILE=OUTDIR+sub_id+'.fasta'\n",
        "  ####Get chain break#### Note! This is now set for trimer subcomponents\n",
        "  CB=np.cumsum([int(x) for x in sub_ids[sub_id]])\n",
        "  CB = [str(x) for x in CB]\n",
        "  ####Get MSAs####\n",
        "  #HHblits paired\n",
        "  PAIREDMSA=OUTDIR+sub_id+'_paired.a3m'\n",
        "  ##HHblits block diagonalized\n",
        "  BLOCKEDMSA=OUTDIR+sub_id+'_blocked.a3m'\n",
        "  MSAS=[PAIREDMSA,BLOCKEDMSA] #Comma separated list of msa paths\n",
        "  run_alphafold_colab.main([MODEL_NAME], 1, MAX_RECYCLES, STRUCTURE_DIR, FASTAFILE, sub_id, MSAS, CB, OUTDIR)"
      ],
      "metadata": {
        "id": "Fw0kw1KT3Sd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COMPLEXDIR=OUTDIR+'/assembly/complex/' #Where all the output for the complex assembly will be directed\n",
        "PAIRDIR=OUTDIR+'/assembly/pairs/'\n",
        "META=OUTDIR+'/assembly/meta.csv' #where to write all interactions"
      ],
      "metadata": {
        "id": "3GhXImpljZOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 3: ASSEMBLY PIPELINE\n",
        "#@markdown Prepare the assembly\n",
        "COMPLEXDIR=OUTDIR+'/assembly/complex/' #Where all the output for the complex assembly will be directed\n",
        "PAIRDIR=OUTDIR+'/assembly/pairs/'\n",
        "META=OUTDIR+'/assembly/meta.csv' #where to write all interactions\n",
        "from complex_assembly import prepare_assembly_colab\n",
        "#Make complex directory\n",
        "if not os.path.exists(COMPLEXDIR):\n",
        "  os.mkdir(OUTDIR+'/assembly')\n",
        "  os.mkdir(COMPLEXDIR)\n",
        "#Rewrite the FoldDock preds to have separate chains according to the fasta file seqlens\n",
        "files = glob.glob(OUTDIR+ID+'*/*1.pdb')\n",
        "if len(files)>0:\n",
        "    for pdbname in files:\n",
        "        chains = prepare_assembly_colab.read_all_chains_coords(pdbname)\n",
        "        if len(chains.keys())>1:\n",
        "            continue\n",
        "        subid = pdbname.split('/')[-2]\n",
        "        print(subid)\n",
        "        #Rewrite the files\n",
        "        prepare_assembly_colab.write_pdb(chains, pdbname.split('.')[0]+'_rw'+'.pdb')\n",
        "\n",
        "#Copy the predictions to reflect all chains\n",
        "prepare_assembly_colab.copy_uints(ID, OUTDIR, OUTDIR+'/assembly/', USEQS,INTERACTIONS, CHAINS, GET_ALL, SUBSIZE)\n",
        "##Rewrite AF predicted complexes to have proper numbering and chain labels\n",
        "files = glob.glob(OUTDIR+'/assembly/'+ID+'*/*.pdb')\n",
        "if len(files)>0:\n",
        "    for pdbname in files:\n",
        "        chains = prepare_assembly_colab.read_all_chains_coords(pdbname)\n",
        "        subid = pdbname.split('/')[-2]\n",
        "        chain_names = subid.split('_')[-1]\n",
        "        #Rewrite the files\n",
        "        prepare_assembly_colab.write_pdb_chain_labels(chains, chain_names, OUTDIR+'/assembly/'+subid+'.pdb')\n",
        "#Write all pairs\n",
        "#It is necessary that the first unique chain is named A-..N for and the second N-... and so on\n",
        "if not os.path.exists(PAIRDIR):\n",
        "  os.mkdir(PAIRDIR)\n",
        "\n",
        "prepare_assembly_colab.get_all_pairs(OUTDIR+'/assembly/', PAIRDIR, INTERACTIONS, GET_ALL, META)\n",
        "#Cleanup\n",
        "for filename in glob.glob(OUTDIR+'/assembly/'+ID+'_*.pdb'):\n",
        "  os.remove(filename)\n",
        "for dir in glob.glob(OUTDIR+'/assembly/'+ID+'_*'):\n",
        "  if os.path.isdir(dir)==True:\n",
        "    shutil.rmtree(dir)\n"
      ],
      "metadata": {
        "id": "_Uzmm0xcibSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Assemble: find the best non-overlapping path that connect all nodes using Monte Carlo tree search\n",
        "META_DF=pd.read_csv(META)\n",
        "CHAIN_SEQS=pd.read_csv(OUTDIR+'/assembly/'+ID+'_chains.csv')\n",
        "from complex_assembly import mcts_colab\n",
        "mcts_colab.assemble(META_DF, PAIRDIR, OUTDIR+'/assembly/plddt/', USEQS, CHAIN_SEQS, COMPLEXDIR)\n"
      ],
      "metadata": {
        "id": "qY3K-pKQgO4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##@title Score the assembly\n",
        "from complex_assembly import score_entire_complex_colab\n",
        "score_entire_complex_colab.main(ID, COMPLEXDIR+'best_complex.pdb', COMPLEXDIR+'optimal_path.csv', USEQS, CHAINS, COMPLEXDIR+'scores.csv')\n",
        "\n",
        "#Clean up files used in the assembly and scoring\n",
        "#Pair dir\n",
        "try:\n",
        "  shutil.rmtree(PAIRDIR)\n",
        "  shutil.rmtree(OUTDIR+'/assembly/plddt/')\n",
        "  for subcomponent_dir in glob.glob(OUTDIR+ID+'*_*'):\n",
        "    if os.path.isdir(subcomponent_dir)==True:\n",
        "      shutil.rmtree(subcomponent_dir)\n",
        "  \n",
        "except:\n",
        "  'No dirs to remove'\n"
      ],
      "metadata": {
        "id": "P_QbPiT_iGs6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a339ba-a022-4db0-b12c-49f8016391cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mpDockQ: 0.7585587929480845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display 3D structure {run: \"auto\"}\n",
        "#From: https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/AlphaFold2.ipynb\n",
        "import py3Dmol\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js',)\n",
        "view.addModel(open(COMPLEXDIR+'best_complex.pdb','r').read(),'pdb')\n",
        "\n",
        "\n",
        "for n,chain,color in zip(range(len(CHAINS)),list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"),\n",
        "                     [\"lime\",\"cyan\",\"magenta\",\"yellow\",\"salmon\",\"white\",\"blue\",\"orange\",\n",
        "                     \"grey\",\"brown\",\"lime\",\"cyan\",\"magenta\",\"yellow\",\"salmon\",\"white\",\"blue\",\"orange\",\n",
        "                     \"grey\",\"brown\",\"lime\",\"cyan\",\"magenta\",\"yellow\",\"salmon\",\"white\",\"blue\",\"orange\",\n",
        "                     \"grey\",\"brown\"]):\n",
        "      view.setStyle({'chain':chain},{'cartoon': {'color':color}})\n",
        "#view.setStyle({'cartoon': {'color':'spectrum'}})\n",
        "view.zoomTo()\n",
        "view.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "cY0uUyjTijwN",
        "outputId": "93e77b55-8c8a-4151-c007-615afac4390a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e867b3ba20a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title Display 3D structure {run: \"auto\"}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#From: https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/AlphaFold2.ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpy3Dmol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'py3Dmol'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}